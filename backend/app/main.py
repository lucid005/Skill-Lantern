"""
Skill Lantern Backend - FastAPI Application
AI-Powered Career Guidance System

Main entry point for the FastAPI backend.
"""

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
import logging

from app.config import settings
from app.models.schemas import HealthResponse
from app.routers import career, roadmap, colleges, recommendations
from app.services.ollama_service import ollama_service
from app.services.college_service import college_service
from app.models.career_predictor import career_predictor

# Configure logging
logging.basicConfig(
    level=logging.DEBUG if settings.debug else logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    Application lifespan handler.
    Runs on startup and shutdown.
    """
    # Startup
    logger.info("üöÄ Starting Skill Lantern Backend...")
    
    # Load college data
    logger.info("üìö Loading college data...")
    if college_service.load_data():
        logger.info("‚úÖ College data loaded successfully")
    else:
        logger.warning("‚ö†Ô∏è Failed to load college data - check CSV path")
    
    # Load career data
    logger.info("üìä Loading career data...")
    if career_predictor.load_career_data():
        logger.info("‚úÖ Career data loaded successfully")
    else:
        logger.warning("‚ö†Ô∏è Failed to load career data - using rule-based prediction")
    
    # Try to load XGBoost model
    logger.info("ü§ñ Loading XGBoost model...")
    if career_predictor.load_model():
        logger.info("‚úÖ XGBoost model loaded")
    else:
        logger.info("‚ÑπÔ∏è Using rule-based prediction (XGBoost model not found)")
    
    # Check Ollama connection
    logger.info("üîó Checking Ollama connection...")
    if await ollama_service.check_health():
        logger.info(f"‚úÖ Ollama is running (model: {settings.ollama_model})")
        models = await ollama_service.list_models()
        logger.info(f"üìã Available models: {models}")
    else:
        logger.warning("‚ö†Ô∏è Ollama is not accessible - LLM features will be limited")
    
    logger.info("‚ú® Skill Lantern Backend is ready!")
    
    yield
    
    # Shutdown
    logger.info("üëã Shutting down Skill Lantern Backend...")


# Create FastAPI app
app = FastAPI(
    title="Skill Lantern API",
    description="""
    AI-Powered Career Guidance System for Nepal
    
    ## Features
    
    * **Career Prediction** - XGBoost-based career recommendations
    * **Career Roadmap** - LLaMA-generated learning paths
    * **College Recommendations** - Nepal college suggestions
    * **Full Guidance** - Complete career assessment
    
    ## Tech Stack
    
    * FastAPI + Python
    * XGBoost for career prediction
    * Ollama/LLaMA for LLM inference
    * Nepal college dataset
    """,
    version="1.0.0",
    lifespan=lifespan,
    docs_url="/docs",
    redoc_url="/redoc"
)

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.cors_origins_list,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# Include routers
app.include_router(career.router, prefix="/api")
app.include_router(roadmap.router, prefix="/api")
app.include_router(colleges.router, prefix="/api")
app.include_router(recommendations.router, prefix="/api")


# Root endpoints
@app.get("/", tags=["Root"])
async def root():
    """Root endpoint - API information."""
    return {
        "name": "Skill Lantern API",
        "version": "1.0.0",
        "description": "AI-Powered Career Guidance System for Nepal",
        "docs": "/docs",
        "health": "/api/health"
    }


@app.get("/api/health", response_model=HealthResponse, tags=["Health"])
async def health_check():
    """
    Health check endpoint.
    
    Returns status of:
    - API server
    - Ollama/LLM connection
    - XGBoost model
    """
    ollama_healthy = await ollama_service.check_health()
    
    return HealthResponse(
        status="healthy",
        ollama_status="connected" if ollama_healthy else "disconnected",
        model_loaded=career_predictor.model_loaded,
        version="1.0.0"
    )


@app.get("/api/config", tags=["Config"])
async def get_config():
    """Get non-sensitive configuration info."""
    return {
        "ollama_model": settings.ollama_model,
        "ollama_host": settings.ollama_host,
        "debug": settings.debug
    }


# Run with uvicorn
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "app.main:app",
        host=settings.host,
        port=settings.port,
        reload=settings.debug
    )
